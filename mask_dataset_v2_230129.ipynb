{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BGWdA9-2GjzlSQy8_yYN9ltLs7rXpb94",
      "authorship_tag": "ABX9TyMN8mI4jJJ5VjQZQUTw7Xqv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeJaeEun0/Study_for_miniproject/blob/main/mask_dataset_v2_230129.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다른 데이터셋 훈련시키기\n",
        "데이터\n",
        "\n",
        "참고한 사이트\n",
        "https://www.kaggle.com/code/charlessamuel/face-mask-detection-pytorch"
      ],
      "metadata": {
        "id": "Nyfg9k7YbLbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim # 최적화 알고리즘 구현\n",
        "from torch.optim import lr_scheduler # 학습률 lr을 구현\n",
        "import numpy as np\n",
        "import torchvision # datasets, models, transforms으로 구성\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder, DatasetFolder\n",
        "import matplotlib.pyplot as plt\n",
        "import time # 시간 관련 모듈\n",
        "import os # 운영체제\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil # 폴더 복사\n",
        "import time # 시간 관련 계산\n",
        "import copy # 파일 복사"
      ],
      "metadata": {
        "id": "U6K-bt_lWBS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, SubsetRandomSampler, Subset, WeightedRandomSampler\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import ImageFolder, DatasetFolder\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "import PIL\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Kc3uRD8KVwzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPGVIf50ISB1",
        "outputId": "8bfede62-542e-4f23-9fa6-5fce47029251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating image datasets an data loaders for train and test using the experiments folder split - 새로운 데이터셋의 경우 train과 test로 나눌 필요가 있음"
      ],
      "metadata": {
        "id": "K1jgK4Q6YU1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments_path= '/content/drive/MyDrive/mask/dataset2/data'"
      ],
      "metadata": {
        "id": "XprtTrrGcQXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = { # 딕셔너리 형태로 train, test 만들기\n",
        "    'train': transforms.Compose([ # transforms를 통해 전처리 및 정규화를 위해서 사용\n",
        "        transforms.RandomResizedCrop(224), # 이미지의 임의 부분을 잘라내고 지정된 크기로 조정 => 224인 정사각형, 종류가 다양해야 학습이 잘됨\n",
        "        transforms.ToTensor(), # PIM image나 numpy.ndarray를 텐서로 바꿈\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 평균과 표준편차로 텐서 이미지를 정규화 \n",
        "    ]), \n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256), \n",
        "        transforms.CenterCrop(224), # resize하고 가운데를 중심으로 자르기(크기 맞춤) \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 컬러값은 거의 고정, 흑백으로 할 경우 변할 수 있음\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "QOkW-tBPY3YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test, train나누는 코드필요"
      ],
      "metadata": {
        "id": "udZnf4fDWux8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(experiments_path, x), data_transforms[x]) for x in ['train', 'test']}"
      ],
      "metadata": {
        "id": "Gchhd95lY3UE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "af16e2f1-5f10-42ac-9842-b1e3f5169cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9e671ba0f07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiments_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-9e671ba0f07a>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiments_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/mask/dataset2/data/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.class_to_idx\n",
        "\n",
        "dataset.class_to_idx = {'with_mask':1, 'without_mask':0}\n",
        "dataset.class_to_idx"
      ],
      "metadata": {
        "id": "DaZSKEkZlqHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2class = {v: k for k, v in dataset.class_to_idx.items()}\n",
        "idx2class"
      ],
      "metadata": {
        "id": "8-jaXKB8Y3Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_distribution(dataset_obj):\n",
        "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
        "    \n",
        "    for element in dataset_obj:\n",
        "        y_lbl = element[1]\n",
        "        y_lbl = idx2class[y_lbl]\n",
        "        count_dict[y_lbl] += 1\n",
        "            \n",
        "    return count_dict\n",
        "print(\"Distribution of classes: \\n\", get_class_distribution(dataset))"
      ],
      "metadata": {
        "id": "DXApZskhY3Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = random_split(dataset, (6000, 1553))"
      ],
      "metadata": {
        "id": "Sfxn2ydsY3GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=4, num_workers=2)\n",
        "val_loader = DataLoader(dataset=val_dataset, shuffle=False, batch_size=4, num_workers=2)\n",
        "print(\"Length of the train_loader:\", len(train_loader))\n",
        "print(\"Length of the val_loader:\", len(val_loader))"
      ],
      "metadata": {
        "id": "W6qqsA46ofZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "classes = ('with_mask', 'without_mask')\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "EiTkTcVrogy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "itRbm5lwojIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "Elty-2JLolVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def images_to_probs(net, images):\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.numpy())\n",
        "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "def evaluate(net, dataloader):\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images, labels.numpy()\n",
        "\n",
        "            preds, probs = images_to_probs(net, images)\n",
        "\n",
        "            total += len(labels)\n",
        "            correct += (preds == labels).sum()\n",
        "    return correct/total * 100\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train(net, loss_fn, opt, dataloader, epochs):\n",
        "    num_steps = 0\n",
        "    min_loss = 1e+10\n",
        "\n",
        "    for epoch in tqdm(range(1, epochs+1), total=epochs, desc='Training'):\n",
        "        running_loss = []\n",
        "        net.train() # Setting the network to TRAIN mode\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images, labels\n",
        "            num_steps += 1\n",
        "\n",
        "            # FP\n",
        "            outs = net(images)\n",
        "            loss = loss_fn(outs, labels)\n",
        "\n",
        "            # Logging the loss value\n",
        "            running_loss.append(loss.item())\n",
        "\n",
        "            # BP\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            # Clearing the RAM\n",
        "            #del images, labels, outs\n",
        "            #torch.device('cpu').empty_cache()\n",
        "        \n",
        "        epoch_loss = sum(running_loss) / len(running_loss)\n",
        "        acc = evaluate(net, dataloader)\n",
        "        print(\"Accuracy: \",acc)\n",
        "        print(\"loss: \",epoch_loss)\n",
        "        # Model Checkpointing\n",
        "        if epoch_loss < min_loss:\n",
        "            min_loss = epoch_loss\n",
        "            bestmodel = net.state_dict()\n",
        "    #torch.save(bestmodel,'{0}_{1:0.4f}.pth'.format('classifier',min_loss))\n",
        "    return None\n",
        "\n",
        "    print('Training finished!!!')"
      ],
      "metadata": {
        "id": "m99VkuA9EKuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(net, criterion, optimizer, train_loader, 2)"
      ],
      "metadata": {
        "id": "V_TrpL15EJPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testimg, testlab = next(iter(val_loader))\n",
        "testimg, testlab = testimg, testlab\n",
        "\n",
        "pred = net(testimg)\n",
        "predlab = torch.argmax(pred,axis=1)\n",
        "    "
      ],
      "metadata": {
        "id": "rU2W64Lno6LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted\",[i for i in predlab])\n",
        "print(\"Actual\",[i for i in testlab])\n",
        "for i in predlab:\n",
        "  if i == 0:\n",
        "    print(\"without_mask\")\n",
        "  else:\n",
        "    print(\"with_mask\")\n",
        "print(\"______________________________________________________________________________________________________________\")\n",
        "for i in testlab:\n",
        "  if i == 0:\n",
        "    print(\"without_mask\")\n",
        "  else:\n",
        "    print(\"with_mask\")"
      ],
      "metadata": {
        "id": "2ADAVemtpBJB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}